{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import copy\n", "import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "from tqdm import tqdm\n", "from torch import optim\n", "from utils import *\n", "from modules import UNet_conditional, EMA\n", "import logging\n", "from torch.utils.tensorboard import SummaryWriter"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Diffusion:\n", "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=256, device=\"cuda\"):\n", "        self.noise_steps = noise_steps\n", "        self.beta_start = beta_start\n", "        self.beta_end = beta_end\n", "        self.beta = self.prepare_noise_schedule().to(device)\n", "        self.alpha = 1. - self.beta\n", "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n", "        self.img_size = img_size\n", "        self.device = device\n", "    def prepare_noise_schedule(self):\n", "        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n", "    def noise_images(self, x, t):\n", "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n", "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n", "        \u0190 = torch.randn_like(x)\n", "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * \u0190, \u0190\n", "    def sample_timesteps(self, n):\n", "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n", "    def sample(self, model, n, labels, cfg_scale=3):\n", "        logging.info(f\"Sampling {n} new images....\")\n", "        model.eval()\n", "        with torch.no_grad():\n", "            x = torch.randn((n, 3, self.img_size, self.img_size)).to(self.device)\n", "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n", "                t = (torch.ones(n) * i).long().to(self.device)\n", "                predicted_noise = model(x, t, labels)\n", "                if cfg_scale > 0:\n", "                    uncond_predicted_noise = model(x, t, None)\n", "                    predicted_noise = torch.lerp(uncond_predicted_noise, predicted_noise, cfg_scale)\n", "                alpha = self.alpha[t][:, None, None, None]\n", "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n", "                beta = self.beta[t][:, None, None, None]\n", "                if i > 1:\n", "                    noise = torch.randn_like(x)\n", "                else:\n", "                    noise = torch.zeros_like(x)\n", "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n", "        model.train()\n", "        x = (x.clamp(-1, 1) + 1) / 2\n", "        x = (x * 255).type(torch.uint8)\n", "        return x"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train(args):\n", "    setup_logging(args.run_name)\n", "    device = args.device\n", "    dataloader = get_data(args)\n", "    model = UNet_conditional(num_classes=args.num_classes).to(device)\n", "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n", "    mse = nn.MSELoss()\n", "    diffusion = Diffusion(img_size=args.image_size, device=device)\n", "    logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\n", "    l = len(dataloader)\n", "    ema = EMA(0.995)\n", "    ema_model = copy.deepcopy(model).eval().requires_grad_(False)\n", "    for epoch in range(args.epochs):\n", "        logging.info(f\"Starting epoch {epoch}:\")\n", "        pbar = tqdm(dataloader)\n", "        for i, (images, labels) in enumerate(pbar):\n", "            images = images.to(device)\n", "            labels = labels.to(device)\n", "            t = diffusion.sample_timesteps(images.shape[0]).to(device)\n", "            x_t, noise = diffusion.noise_images(images, t)\n", "            if np.random.random() < 0.1:\n", "                labels = None\n", "            predicted_noise = model(x_t, t, labels)\n", "            loss = mse(noise, predicted_noise)\n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            optimizer.step()\n", "            ema.step_ema(ema_model, model)\n", "            pbar.set_postfix(MSE=loss.item())\n", "            logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n", "        if epoch % 10 == 0:\n", "            labels = torch.arange(10).long().to(device)\n", "            sampled_images = diffusion.sample(model, n=len(labels), labels=labels)\n", "            ema_sampled_images = diffusion.sample(ema_model, n=len(labels), labels=labels)\n", "            plot_images(sampled_images)\n", "            save_images(sampled_images, os.path.join(\"results\", args.run_name, f\"{epoch}.jpg\"))\n", "            save_images(ema_sampled_images, os.path.join(\"results\", args.run_name, f\"{epoch}_ema.jpg\"))\n", "            torch.save(model.state_dict(), os.path.join(\"models\", args.run_name, f\"ckpt.pt\"))\n", "            torch.save(ema_model.state_dict(), os.path.join(\"models\", args.run_name, f\"ema_ckpt.pt\"))\n", "            torch.save(optimizer.state_dict(), os.path.join(\"models\", args.run_name, f\"optim.pt\"))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def launch():\n", "    import argparse\n", "    parser = argparse.ArgumentParser()\n", "    args = parser.parse_args()\n", "    args.run_name = \"DDPM_conditional\"\n", "    args.epochs = 300\n", "    args.batch_size = 14\n", "    args.image_size = 64\n", "    args.num_classes = 10\n", "    args.dataset_path = r\"C:\\Users\\dome\\datasets\\cifar10\\cifar10-64\\train\"\n", "    args.device = \"cuda\"\n", "    args.lr = 3e-4\n", "    train(args)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}